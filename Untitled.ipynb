{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datas/training_set_rel3.tsv',sep='\\t', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  9,  7, 10,  6, 12,  4,  3, 11,  2,  5,  1,  0, 15, 13, 17, 23,\n",
       "       16, 18, 19, 14, 21, 24, 20, 22, 34, 46, 40, 30, 26, 41, 31, 44, 36,\n",
       "       43, 45, 35, 42, 33, 38, 47, 32, 50, 39, 37, 55, 60, 28, 49, 29, 27,\n",
       "       25, 48], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['domain1_score'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = df.shape[0]\n",
    "essays = df['essay'].values\n",
    "\n",
    "#initialize dataframe columns\n",
    "df['essay length'] = np.nan \n",
    "df['sentence length'] = np.nan\n",
    "df['average word length'] = np.nan \n",
    "df['sentiment'] = np.nan \n",
    "df['spelling'] = np.nan\n",
    "df['grammar'] = np.nan\n",
    "\n",
    "#check computation time\n",
    "start = time.time()\n",
    "\n",
    "#loop through each essay\n",
    "for i in range(num_rows):  \n",
    "    \n",
    "    blob = TextBlob(essays[i])\n",
    "    \n",
    "    #number of words\n",
    "    df.set_value(i,'essay length',len(blob.words))\n",
    "    \n",
    "    #sentence length\n",
    "    sentence_len = [len(sentence.split(' ')) for sentence in blob.sentences]\n",
    "    df.set_value(i,'sentence length', sum(sentence_len) / len(sentence_len))\n",
    "    \n",
    "    #essay sentiment\n",
    "    df.set_value(i,'sentiment',blob.sentiment.polarity)\n",
    "    \n",
    "    #average word length\n",
    "    word_len = [len(word) for word in blob.words]\n",
    "    df.set_value(i,'average word length',sum(word_len) / len(word_len))\n",
    "    \n",
    "    #number of grammar mistakes\n",
    "    tool = language_check.LanguageTool('en-US')\n",
    "    matches = tool.check(essays[i])\n",
    "    df.set_value(i,'grammar',len(matches))\n",
    "    \n",
    "    #spelling mistakes\n",
    "    #this exception is made to catch any spelling errors cause by \\u2019 apostraphies\n",
    "    try:\n",
    "        d = enchant.Dict('en_US')\n",
    "        words = character_filter(blob.words)\n",
    "        checks = [d.check(word) for word in words]\n",
    "        df.set_value(i,'spelling', checks.count(False))    \n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"I feel that computers do take away from peoples life and aren't as important than the other factors of life. First of all you know that the world is becoming obease because of lack of exercise. Also people don't realize that warming is becomeing a big problum. Finally familys arn't as close as they used to be. these are all the reasons why computers arn't important to human socioty. First of the world is becomeing obease and cumputers play a huge part in this. Computers don't make people exercise they basicly just sit down on there couch and use the computer this won't help amarica get back into shape.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = (len(TextBlob(text[0]).words))\n",
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(text[0])\n",
    "sentence_len = len([len(sentence.split(' ')) for sentence in TextBlob(text[0]).sentences])\n",
    "sentence_len = len(sentence_len)\n",
    "sentence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1438034188034188"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_essay = TextBlob(text[0]).sentiment.polarity\n",
    "sentiment_essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.2956521739130435"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_len = [len(word) for word in blob.words]\n",
    "sum(word_len)/len(word_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = language_check.LanguageTool('en-US')\n",
    "matches = tool.check(text[0])\n",
    "len(mathces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import language_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextBlob.Word(text[0]).spellcheck()\n",
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "every = 0\n",
    "for wor in TextBlob(text[0]).words:\n",
    "    w = Word(wor)\n",
    "    if len(w.spellcheck()) > 1:\n",
    "         every += 1  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
